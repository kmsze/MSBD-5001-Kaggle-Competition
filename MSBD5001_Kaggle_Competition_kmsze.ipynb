{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 949
    },
    "colab_type": "code",
    "id": "Kjb9Q_0wGXDz",
    "outputId": "b4e50b4d-1248-4efe-eebd-fe66e07d6398"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "def drop_df_columns(df_train, df_test, col_name):\n",
    "    df_train = df_train.drop(labels=col_name, axis=1)\n",
    "    df_test = df_test.drop(labels=col_name, axis=1)\n",
    "    return df_train, df_test\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def deeper_model():\n",
    "    model = Sequential()\n",
    "    # Input Layer\n",
    "    model.add(Dense(16, input_dim=6, kernel_initializer='normal', activation='relu'))\n",
    "    # Hidden layers\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    # Output Layer\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def deeper_model_with_dropout():\n",
    "    model = Sequential()\n",
    "    # Input Layer\n",
    "    model.add(Dense(16, input_dim=6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2, input_shape=(10,)))\n",
    "    # Hidden layers\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Output Layer\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def deeper_model_2nd():\n",
    "    model = Sequential()\n",
    "    # Input Layer\n",
    "    model.add(Dense(16, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "    # Hidden layers\n",
    "    model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "    # Output Layer\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def wider_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def run_model(**kwargs):\n",
    "    print(kwargs)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('mlp', KerasRegressor(\n",
    "        build_fn=kwargs['model'],\n",
    "        epochs=kwargs['num_of_epochs'],\n",
    "        batch_size=5,\n",
    "        verbose=0,\n",
    "    )))\n",
    "    pipeline = Pipeline(estimators)\n",
    "   \n",
    "    kfold = KFold(n_splits=kwargs['cv'], shuffle=True, random_state=seed)\n",
    "    results = cross_val_score(pipeline, X, Y, cv=kfold, verbose=0)\n",
    "    print(\"%s: %.2f (%.2f) MSE\" % (kwargs['model_name'], results.mean(), results.std()))\n",
    "    print(results)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "9_fSB2JVGmfC",
    "outputId": "0dbf78f0-2681-45f6-b628-7ec6ac5c12e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>combine</th>\n",
       "      <th>penalty_elasticnet</th>\n",
       "      <th>penalty_l1</th>\n",
       "      <th>penalty_l2</th>\n",
       "      <th>penalty_none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>20.431966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.569294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20.637689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21.195375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>19.171336</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_jobs    combine  penalty_elasticnet  penalty_l1  penalty_l2  penalty_none\n",
       "0      16  20.431966                   0           0           0             1\n",
       "1       1  20.569294                   0           1           0             0\n",
       "2       2  20.637689                   0           0           0             1\n",
       "3       4  21.195375                   0           0           0             1\n",
       "4       2  19.171336                   1           0           0             0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read train.csv and test.csv to pandas dataframe\n",
    "df_train = pd.read_csv(\"train.csv\", header='infer', na_values='?')\n",
    "df_test = pd.read_csv(\"test.csv\", header='infer', na_values='?')\n",
    "df_train_label = df_train[\"time\"]\n",
    "df_train = df_train.drop(labels=\"time\", axis=1)\n",
    "df_train = df_train.drop(labels=\"id\", axis=1)\n",
    "df_test = df_test.drop(labels=\"id\", axis=1)\n",
    "\n",
    "# Create a new features called combine which is a combination of log transform of 5 feaures\n",
    "# including max_iter, n_samples, n_features, n_classes and alpha\n",
    "df_train[\"combine\"] = (np.log1p(df_train[\"max_iter\"]) + np.log1p(df_train[\"n_samples\"]) + np.log1p(df_train[\"n_features\"]) + \n",
    "                       np.log1p(df_train[\"n_classes\"]) + np.log1p(df_train[\"alpha\"]))\n",
    "df_test[\"combine\"] = (np.log1p(df_test[\"max_iter\"]) + np.log1p(df_test[\"n_samples\"]) + np.log1p(df_test[\"n_features\"]) + \n",
    "                       np.log1p(df_test[\"n_classes\"]) + np.log1p(df_test[\"alpha\"]))\n",
    "\n",
    "# Drop all less correlated features\n",
    "df_train, df_test = drop_df_columns(df_train, df_test, \"l1_ratio\")\n",
    "df_train, df_test = drop_df_columns(df_train, df_test, \"alpha\")\n",
    "df_train, df_test = drop_df_columns(df_train, df_test, \"max_iter\")\n",
    "df_train, df_test = drop_df_columns(df_train, df_test, \"random_state\")\n",
    "df_train, df_test = drop_df_columns(df_train, df_test, \"n_samples\")\n",
    "df_train, df_test = drop_df_columns(df_train, df_test, \"n_features\")\n",
    "df_train, df_test = drop_df_columns(df_train, df_test, \"n_classes\")\n",
    "df_train, df_test = drop_df_columns(df_train, df_test, \"n_clusters_per_class\")\n",
    "df_train, df_test = drop_df_columns(df_train, df_test, \"n_informative\")\n",
    "df_train, df_test = drop_df_columns(df_train, df_test, \"flip_y\")\n",
    "df_train, df_test = drop_df_columns(df_train, df_test, \"scale\")\n",
    "\n",
    "df_train.loc[df_train['n_jobs'] == -1, 'n_jobs'] = 16\n",
    "df_test.loc[df_test['n_jobs'] == -1, 'n_jobs'] = 16\n",
    "\n",
    "# One hot encoding for penalty feature\n",
    "df_train = pd.get_dummies(df_train, columns=[\"penalty\"])\n",
    "df_test = pd.get_dummies(df_test, columns=[\"penalty\"])\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "MVFHvAgRGqLe",
    "outputId": "be10dd17-a799-447b-e4df-0df0abb5aba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': <function deeper_model at 0x000001ABD97142F0>, 'model_name': 'Deep', 'num_of_epochs': 100, 'cv': 3}\n",
      "Deep: -1.73 (0.62) MSE\n",
      "[-0.85749478 -2.09410005 -2.23606177]\n",
      "-1.1293861901853233\n"
     ]
    }
   ],
   "source": [
    "X = df_train.values\n",
    "Y = df_train_label.values.ravel()\n",
    "deep = run_model(model=deeper_model, model_name=\"Deep\", num_of_epochs=100, cv=3)\n",
    "deep.fit(X, Y)\n",
    "prediction_result = deep.predict(df_test.values)\n",
    "print(deep.score(X, Y))\n",
    "\n",
    "# Predictation result is saved to submission.csv file\n",
    "test_id = np.arange(0, 100)\n",
    "my_submission = pd.DataFrame({'Id': test_id, 'time': prediction_result})\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "keras_1.43877.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
